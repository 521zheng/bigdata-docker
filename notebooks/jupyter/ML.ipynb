{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking org.bdgenomics.adam:adam-core-spark2_2.11:0.24.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree-tmp-dir13940453237730335/toree_add_deps/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree-tmp-dir13940453237730335/toree_add_deps/https/repo1.maven.org/maven2/org/bdgenomics/adam/adam-core-spark2_2.11/0.24.0/adam-core-spark2_2.11-0.24.0.jar\n",
      "-> New file at /tmp/toree-tmp-dir13940453237730335/toree_add_deps/https/repo1.maven.org/maven2/org/bdgenomics/adam/adam-core-spark2_2.11/0.24.0/adam-core-spark2_2.11-0.24.0.pom\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking comp.bio.aging:adam-playground_2.11:0.0.13 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree-tmp-dir13940453237730335/toree_add_deps/\n",
      "-> https://dl.bintray.com/comp-bio-aging/main/\n",
      "-> https://repo1.maven.org/maven2\n"
     ]
    }
   ],
   "source": [
    "%AddDeps org.bdgenomics.adam adam-core-spark2_2.11 0.24.0\n",
    "%AddDeps comp.bio.aging adam-playground_2.11 0.0.13 --repository https://dl.bintray.com/comp-bio-aging/main/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking org.apache.hadoop:hadoop-azure:2.7.6 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree-tmp-dir13940453237730335/toree_add_deps/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree-tmp-dir13940453237730335/toree_add_deps/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure/2.7.6/hadoop-azure-2.7.6.jar\n",
      "-> New file at /tmp/toree-tmp-dir13940453237730335/toree_add_deps/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure/2.7.6/hadoop-azure-2.7.6.pom\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking com.microsoft.azure:azure-storage:2.0.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree-tmp-dir13940453237730335/toree_add_deps/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree-tmp-dir13940453237730335/toree_add_deps/https/repo1.maven.org/maven2/com/microsoft/azure/azure-storage/2.0.0/azure-storage-2.0.0.jar\n",
      "-> New file at /tmp/toree-tmp-dir13940453237730335/toree_add_deps/https/repo1.maven.org/maven2/com/microsoft/azure/azure-storage/2.0.0/azure-storage-2.0.0.pom\n"
     ]
    }
   ],
   "source": [
    "%AddDeps org.apache.hadoop hadoop-azure 2.7.6\n",
    "%AddDeps com.microsoft.azure azure-storage 2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  org.apache.spark._\n",
    "import org.apache.spark.sql.{DataFrame, Encoders, SparkSession}\n",
    "import org.apache.spark.sql.types.StructType\n",
    "import scala.reflect.runtime.universe._\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "import org.apache.spark.rdd._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparkHadoopConf: (sc: org.apache.spark.SparkContext, acountName: String, accountKey: String)org.apache.spark.SparkContext\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sparkHadoopConf(sc: SparkContext, acountName: String, accountKey: String) = {\n",
    "  sc.hadoopConfiguration.set(\"fs.azure\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\")\n",
    "  sc.hadoopConfiguration.set(\"fs.azure.account.key.\" + acountName + \".blob.core.windows.net\", accountKey)\n",
    "  sc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "azurize: (container: String, accountName: String, blobFile: String)String\n",
       "writeText2Azure: [T](rdd: org.apache.spark.rdd.RDD[T], container: String, accountName: String, blobFile: String)String\n",
       "writeTsv2Azure: (df: org.apache.spark.sql.DataFrame, container: String, accountName: String, blobFile: String)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def azurize(container: String, accountName: String, blobFile: String): String = \"wasbs://\"+container+\"@\"+accountName+\".blob.core.windows.net/\"+blobFile \n",
    "\n",
    "def writeText2Azure[T]( rdd: RDD[T], container: String, accountName: String, blobFile: String ): String =\n",
    "{\n",
    "  val url = azurize(container, accountName, blobFile)\n",
    "  rdd.saveAsTextFile(url)\n",
    "  url\n",
    "}\n",
    "\n",
    "def writeTsv2Azure( df: DataFrame, container: String, accountName: String, blobFile: String ): String =\n",
    "{\n",
    "  val url = azurize(container, accountName, blobFile)\n",
    "  df.write.option(\"sep\",\"\\t\").option(\"header\",\"true\").csv(url)\n",
    "  url\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "account = pipelines1\n",
       "key = \n",
       "connString = DefaultEndpointsProtocol=https;AccountName=pipelines1;AccountKey=;EndpointSuffix=core.windows.net\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "az: (path: String)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DefaultEndpointsProtocol=https;AccountName=pipelines1;AccountKey=;EndpointSuffix=core.windows.net"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val account = \"pipelines1\"\n",
    "val key = \"\"\n",
    "val connString = s\"DefaultEndpointsProtocol=https;AccountName=pipelines1;AccountKey=${key};EndpointSuffix=core.windows.net\"\n",
    "def az(path: String): String = azurize(\"storage\", account, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparkContext = org.apache.spark.SparkContext@50ab59c2\n",
       "spark = org.apache.spark.sql.SparkSession@542f5bed\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://acfd6de92b88:4041)\" target=\"new_tab\">Spark UI: app-20180612163411-0003</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark app-20180612163411-0003: Some(http://acfd6de92b88:4041)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sparkContext = sc\n",
    "sparkHadoopConf(sparkContext, account, key)\n",
    "  \n",
    "val spark = SparkSession\n",
    "  .builder()\n",
    "  .appName(\"mapping_models\")\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toDouble = UserDefinedFunction(<function1>,DoubleType,Some(List(StringType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "error: error while loading QualifiedTableName, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/QualifiedTableName.class)' has location not matching its contents: contains class QualifiedTableName\n",
       "error: error while loading JavaTypeInference, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/JavaTypeInference.class)' has location not matching its contents: contains class JavaTypeInference\n",
       "error: error while loading FunctionIdentifier, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/FunctionIdentifier.class)' has location not matching its contents: contains class FunctionIdentifier\n",
       "error: error while loading DefinedByConstructorParams, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/DefinedByConstructorParams.class)' has location not matching its contents: contains class DefinedByConstructorParams\n",
       "error: error while loading IdentifierWithDatabase, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/IdentifierWithDatabase.class)' has location not matching its contents: contains class IdentifierWithDatabase\n",
       "error: error while loading SpecializedGetters, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/expressions/SpecializedGetters.class)' has location not matching its contents: contains class SpecializedGetters\n",
       "error: error while loading Decimal, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/Decimal.class)' has location not matching its contents: contains class Decimal\n",
       "error: error while loading ScalaReflection, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/ScalaReflection.class)' has location not matching its contents: contains trait ScalaReflection\n",
       "error: error while loading CatalystTypeConverters, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/CatalystTypeConverters.class)' has location not matching its contents: contains class CatalystTypeConverters\n",
       "error: error while loading package, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/dsl/package.class)' has location not matching its contents: contains package object dsl\n",
       "error: error while loading package, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/util/package.class)' has location not matching its contents: contains package object util\n",
       "error: error while loading package, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/errors/package.class)' has location not matching its contents: contains package object errors\n",
       "error: error while loading ByteType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/ByteType.class)' has location not matching its contents: contains class ByteType\n",
       "error: error while loading PythonUserDefinedType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/PythonUserDefinedType.class)' has location not matching its contents: contains class PythonUserDefinedType\n",
       "error: error while loading Metadata, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/Metadata.class)' has location not matching its contents: contains class Metadata\n",
       "error: error while loading UserDefinedType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/UserDefinedType.class)' has location not matching its contents: contains class UserDefinedType\n",
       "error: error while loading LongType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/LongType.class)' has location not matching its contents: contains class LongType\n",
       "error: error while loading DataTypes, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/DataTypes.class)' has location not matching its contents: contains class DataTypes\n",
       "error: error while loading NumericType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/NumericType.class)' has location not matching its contents: contains class NumericType\n",
       "error: error while loading StructField, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/StructField.class)' has location not matching its contents: contains class StructField\n",
       "error: error while loading MetadataBuilder, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/MetadataBuilder.class)' has location not matching its contents: contains class MetadataBuilder\n",
       "error: error while loading FractionalType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/FractionalType.class)' has location not matching its contents: contains class FractionalType\n",
       "error: error while loading TypeCollection, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/TypeCollection.class)' has location not matching its contents: contains class TypeCollection\n",
       "error: error while loading DoubleType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/DoubleType.class)' has location not matching its contents: contains class DoubleType\n",
       "error: error while loading AnyDataType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/AnyDataType.class)' has location not matching its contents: contains class AnyDataType\n",
       "error: error while loading StringType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/StringType.class)' has location not matching its contents: contains class StringType\n",
       "error: error while loading ObjectType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/ObjectType.class)' has location not matching its contents: contains class ObjectType\n",
       "error: error while loading NullType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/NullType.class)' has location not matching its contents: contains class NullType\n",
       "error: error while loading ShortType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/ShortType.class)' has location not matching its contents: contains class ShortType\n",
       "error: error while loading IntegralType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/IntegralType.class)' has location not matching its contents: contains class IntegralType\n",
       "error: error while loading AbstractDataType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/AbstractDataType.class)' has location not matching its contents: contains class AbstractDataType\n",
       "error: error while loading Expression, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/expressions/Expression.class)' has location not matching its contents: contains class Expression\n",
       "error: error while loading InterpretedOrdering, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/expressions/InterpretedOrdering.class)' has location not matching its contents: contains class InterpretedOrdering\n",
       "error: error while loading HiveStringType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/HiveStringType.class)' has location not matching its contents: contains class HiveStringType\n",
       "error: error while loading ArrayType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/ArrayType.class)' has location not matching its contents: contains class ArrayType\n",
       "error: error while loading BinaryType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/BinaryType.class)' has location not matching its contents: contains class BinaryType\n",
       "error: error while loading TimestampType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/TimestampType.class)' has location not matching its contents: contains class TimestampType\n",
       "error: error while loading BooleanType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/BooleanType.class)' has location not matching its contents: contains class BooleanType\n",
       "error: error while loading IntegerType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/IntegerType.class)' has location not matching its contents: contains class IntegerType\n",
       "error: error while loading DecimalType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/DecimalType.class)' has location not matching its contents: contains class DecimalType\n",
       "error: error while loading SQLUserDefinedType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/SQLUserDefinedType.class)' has location not matching its contents: contains class SQLUserDefinedType\n",
       "error: error while loading FloatType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/FloatType.class)' has location not matching its contents: contains class FloatType\n",
       "error: error while loading CalendarIntervalType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/CalendarIntervalType.class)' has location not matching its contents: contains class CalendarIntervalType\n",
       "error: error while loading CharType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/CharType.class)' has location not matching its contents: contains class CharType\n",
       "error: error while loading MapType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/MapType.class)' has location not matching its contents: contains class MapType\n",
       "error: error while loading DateType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/DateType.class)' has location not matching its contents: contains class DateType\n",
       "error: error while loading AtomicType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/AtomicType.class)' has location not matching its contents: contains class AtomicType\n",
       "error: error while loading VarcharType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/VarcharType.class)' has location not matching its contents: contains class VarcharType\n",
       "error: error while loading UDTRegistration, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/types/UDTRegistration.class)' has location not matching its contents: contains class UDTRegistration\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,DoubleType,Some(List(StringType)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import spark.implicits._\n",
    "\n",
    "val toDouble = udf[Double, String]( _.toDouble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:100: error: not found: value expressionsPath\n",
       "       val validationPath = expressionsPath + \"/\" + \"validation\"\n",
       "                            ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val gtexPath = \"/GTEx\"\n",
    "val genesPath = az(gtexPath + \"/gtex_genes.tsv\")\n",
    "\n",
    "//val txtPath = az(gtexPath + \"/GTEx_Analysis_2016-01-15_v7_RSEMv1.2.22_transcript_tpm.txt\")\n",
    "//val gctPath = az(gtexPath + \"/GTEx_Analysis_2016-01-15_v7_RNASeQCv1.1.8_gene_tpm.gct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "write: (df: org.apache.spark.sql.DataFrame, url: String, header: Boolean)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def write(df: DataFrame, url: String, header: Boolean = true) = {\n",
    "  df.coalesce(1).write.option(\"sep\",\"\\t\").option(\"header\", header).csv(url)\n",
    "  url\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readTSV: (path: String, header: Boolean, sep: String)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def readTSV(path: String, header: Boolean = false, sep: String = \"\\t\"): DataFrame = spark.read\n",
    "    .option(\"sep\", sep)\n",
    "    .option(\"comment\", \"#\")\n",
    "    .option(\"inferSchema\", true)\n",
    "    .option(\"header\", header)\n",
    "    .option(\"ignoreLeadingWhiteSpace\", true)\n",
    "    .option(\"ignoreTrailingWhiteSpace\", true)\n",
    "    .option(\"ignoreTrailingWhiteSpace\", true)\n",
    "    .option(\"maxColumns\", 150000)\n",
    "    .csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toVectors: (dataFrame: org.apache.spark.sql.DataFrame, columns: Seq[String], output: String)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " def toVectors(dataFrame: DataFrame, columns: Seq[String], output: String) = {  \n",
    "      import org.apache.spark.ml.feature.VectorAssembler\n",
    "      import org.apache.spark.ml.linalg.Vectors\n",
    "\n",
    "      val assembler = new VectorAssembler()\n",
    "        .setInputCols(columns.toArray)\n",
    "        .setOutputCol(output)\n",
    "\n",
    "      assembler.transform(dataFrame.na.fill(0.0, columns).na.fill(\"\")).select(output)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "expressionsPath = expressions\n",
       "byGoPath = expressions/go\n",
       "comparison = expressions/go/gray_whale_with_bowhead_with_minke_with_NMR_with_human_with_mouse_with_cow_full_outer_counts_extended.tsv\n",
       "grouped = expressions/go/grouped\n",
       "ranked = expressions/go/grouped/ranked\n",
       "transcriptsPath = expressions/transcripts\n",
       "validationPath = expressions/validation\n",
       "mouseValidationPath = expressions/validation/mouse\n",
       "jenageValidationPath = expressions/validation/mouse/GSE75192\n",
       "mouseColsValidationPath = expressions/validation/mouse/GSE75192/expressions_columns_GSE75192.tsv\n",
       "mouseRowsValidationPath = expressions/validation/mouse/GSE75192/expressions_rows_GSE75192.tsv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "expressions/validation/mouse/GSE75192/expressions_rows_GSE75192.tsv"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//for testing\n",
    "val expressionsPath = \"expressions\"\n",
    "val byGoPath = expressionsPath + \"/go\"\n",
    "val comparison = byGoPath + \"/gray_whale_with_bowhead_with_minke_with_NMR_with_human_with_mouse_with_cow_full_outer_counts_extended.tsv\"\n",
    "val grouped = byGoPath + \"/grouped\"\n",
    "val ranked = byGoPath + \"/grouped/ranked\"\n",
    "val transcriptsPath = expressionsPath + \"/transcripts\"\n",
    "\n",
    "val validationPath = expressionsPath + \"/\" + \"validation\"\n",
    "val mouseValidationPath = validationPath + \"/\" + \"mouse\"\n",
    "val jenageValidationPath = mouseValidationPath + \"/\" + \"GSE75192\"\n",
    "val mouseColsValidationPath = jenageValidationPath + \"/\" + \"expressions_columns_GSE75192.tsv\"\n",
    "val mouseRowsValidationPath = jenageValidationPath + \"/\" + \"expressions_rows_GSE75192.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val mouseCols = readTSV(az(mouseColsValidationPath), true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%dataframe mouseCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genes = [Name: string, ENSG00000223972.4: string ... 56201 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "error: error while loading KVIterator, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.3.0.jar(org/apache/spark/unsafe/KVIterator.class)' has location not matching its contents: contains class KVIterator\n",
       "error: error while loading UnsafeAlignedOffset, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.3.0.jar(org/apache/spark/unsafe/UnsafeAlignedOffset.class)' has location not matching its contents: contains class UnsafeAlignedOffset\n",
       "error: error while loading Platform, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.3.0.jar(org/apache/spark/unsafe/Platform.class)' has location not matching its contents: contains class Platform\n",
       "error: error while loading UTF8String, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.3.0.jar(org/apache/spark/unsafe/types/UTF8String.class)' has location not matching its contents: contains class UTF8String\n",
       "error: error while loading CalendarInterval, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.3.0.jar(org/apache/spark/unsafe/types/CalendarInterval.class)' has location not matching its contents: contains class CalendarInterval\n",
       "error: error while loading ByteArray, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.3.0.jar(org/apache/spark/unsafe/types/ByteArray.class)' has location not matching its contents: contains class ByteArray\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Name: string, ENSG00000223972.4: string ... 56201 more fields]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val genes = readTSV(genesPath, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "error: error while loading Cross, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/Cross.class)' has location not matching its contents: contains class Cross\n",
       "error: error while loading NaturalJoin, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/NaturalJoin.class)' has location not matching its contents: contains class NaturalJoin\n",
       "error: error while loading LeftExistence, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/LeftExistence.class)' has location not matching its contents: contains class LeftExistence\n",
       "error: error while loading RightOuter, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/RightOuter.class)' has location not matching its contents: contains class RightOuter\n",
       "error: error while loading LeftOuter, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/LeftOuter.class)' has location not matching its contents: contains class LeftOuter\n",
       "error: error while loading ExistenceJoin, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/ExistenceJoin.class)' has location not matching its contents: contains class ExistenceJoin\n",
       "error: error while loading InnerLike, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/InnerLike.class)' has location not matching its contents: contains class InnerLike\n",
       "error: error while loading JoinType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/JoinType.class)' has location not matching its contents: contains class JoinType\n",
       "error: error while loading UsingJoin, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/UsingJoin.class)' has location not matching its contents: contains class UsingJoin\n",
       "error: error while loading FullOuter, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/FullOuter.class)' has location not matching its contents: contains class FullOuter\n",
       "error: error while loading LeftAnti, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/LeftAnti.class)' has location not matching its contents: contains class LeftAnti\n",
       "error: error while loading LeftSemi, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/LeftSemi.class)' has location not matching its contents: contains class LeftSemi\n",
       "error: error while loading Inner, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/Inner.class)' has location not matching its contents: contains class Inner\n",
       "error: error while loading QueryPlan, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/QueryPlan.class)' has location not matching its contents: contains class QueryPlan\n",
       "error: error while loading HintInfo, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/HintInfo.class)' has location not matching its contents: contains class HintInfo\n",
       "error: error while loading ColumnStat, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ColumnStat.class)' has location not matching its contents: contains class ColumnStat\n",
       "error: error while loading ScriptInputOutputSchema, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema.class)' has location not matching its contents: contains class ScriptInputOutputSchema\n",
       "error: error while loading InsertIntoDir, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/InsertIntoDir.class)' has location not matching its contents: contains class InsertIntoDir\n",
       "error: error while loading LogicalPlan, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/LogicalPlan.class)' has location not matching its contents: contains class LogicalPlan\n",
       "error: error while loading Join, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Join.class)' has location not matching its contents: contains class Join\n",
       "error: error while loading FlatMapGroupsInPandas, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/FlatMapGroupsInPandas.class)' has location not matching its contents: contains class FlatMapGroupsInPandas\n",
       "error: error while loading LogicalGroupState, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/LogicalGroupState.class)' has location not matching its contents: contains class LogicalGroupState\n",
       "error: error while loading Pivot, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Pivot.class)' has location not matching its contents: contains class Pivot\n",
       "error: error while loading Generate, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Generate.class)' has location not matching its contents: contains class Generate\n",
       "error: error while loading AppendColumns, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/AppendColumns.class)' has location not matching its contents: contains class AppendColumns\n",
       "error: error while loading HistogramSerializer, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/HistogramSerializer.class)' has location not matching its contents: contains class HistogramSerializer\n",
       "error: error while loading Distinct, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Distinct.class)' has location not matching its contents: contains class Distinct\n",
       "error: error while loading Statistics, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Statistics.class)' has location not matching its contents: contains class Statistics\n",
       "error: error while loading SubqueryAlias, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/SubqueryAlias.class)' has location not matching its contents: contains class SubqueryAlias\n",
       "error: error while loading ObjectConsumer, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ObjectConsumer.class)' has location not matching its contents: contains class ObjectConsumer\n",
       "error: error while loading ProcessingTimeTimeout, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ProcessingTimeTimeout.class)' has location not matching its contents: contains class ProcessingTimeTimeout\n",
       "error: error while loading InsertIntoTable, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/InsertIntoTable.class)' has location not matching its contents: contains class InsertIntoTable\n",
       "error: error while loading MapGroups, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/MapGroups.class)' has location not matching its contents: contains class MapGroups\n",
       "error: error while loading Window, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Window.class)' has location not matching its contents: contains class Window\n",
       "error: error while loading DeserializeToObject, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/DeserializeToObject.class)' has location not matching its contents: contains class DeserializeToObject\n",
       "error: error while loading EventTimeTimeout, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/EventTimeTimeout.class)' has location not matching its contents: contains class EventTimeTimeout\n",
       "error: error while loading MapPartitionsInR, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/MapPartitionsInR.class)' has location not matching its contents: contains class MapPartitionsInR\n",
       "error: error while loading EventTimeWatermark, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/EventTimeWatermark.class)' has location not matching its contents: contains class EventTimeWatermark\n",
       "error: error while loading Sample, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Sample.class)' has location not matching its contents: contains class Sample\n",
       "error: error while loading AppendColumnsWithObject, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/AppendColumnsWithObject.class)' has location not matching its contents: contains class AppendColumnsWithObject\n",
       "error: error while loading Filter, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Filter.class)' has location not matching its contents: contains class Filter\n",
       "error: error while loading TypedFilter, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/TypedFilter.class)' has location not matching its contents: contains class TypedFilter\n",
       "error: error while loading Histogram, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Histogram.class)' has location not matching its contents: contains class Histogram\n",
       "error: error while loading AnalysisBarrier, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/AnalysisBarrier.class)' has location not matching its contents: contains class AnalysisBarrier\n",
       "error: error while loading With, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/With.class)' has location not matching its contents: contains class With\n",
       "error: error while loading MapPartitions, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/MapPartitions.class)' has location not matching its contents: contains class MapPartitions\n",
       "error: error while loading ResolvedHint, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ResolvedHint.class)' has location not matching its contents: contains class ResolvedHint\n",
       "error: error while loading LocalLimit, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/LocalLimit.class)' has location not matching its contents: contains class LocalLimit\n",
       "error: error while loading UnresolvedHint, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/UnresolvedHint.class)' has location not matching its contents: contains class UnresolvedHint\n",
       "error: error while loading Intersect, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Intersect.class)' has location not matching its contents: contains class Intersect\n",
       "error: error while loading OneRowRelation, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/OneRowRelation.class)' has location not matching its contents: contains class OneRowRelation\n",
       "error: error while loading SetOperation, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/SetOperation.class)' has location not matching its contents: contains class SetOperation\n",
       "error: error while loading ScriptTransformation, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ScriptTransformation.class)' has location not matching its contents: contains class ScriptTransformation\n",
       "error: error while loading HistogramBin, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/HistogramBin.class)' has location not matching its contents: contains class HistogramBin\n",
       "error: error while loading RepartitionByExpression, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/RepartitionByExpression.class)' has location not matching its contents: contains class RepartitionByExpression\n",
       "error: error while loading ObjectProducer, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ObjectProducer.class)' has location not matching its contents: contains class ObjectProducer\n",
       "error: error while loading FunctionUtils, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/FunctionUtils.class)' has location not matching its contents: contains class FunctionUtils\n",
       "error: error while loading FlatMapGroupsInR, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/FlatMapGroupsInR.class)' has location not matching its contents: contains class FlatMapGroupsInR\n",
       "error: error while loading Union, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Union.class)' has location not matching its contents: contains class Union\n",
       "error: error while loading LeafNode, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/LeafNode.class)' has location not matching its contents: contains class LeafNode\n",
       "error: error while loading SerializeFromObject, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/SerializeFromObject.class)' has location not matching its contents: contains class SerializeFromObject\n",
       "error: error while loading Command, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Command.class)' has location not matching its contents: contains class Command\n",
       "error: error while loading QueryPlanConstraints, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/QueryPlanConstraints.class)' has location not matching its contents: contains class QueryPlanConstraints\n",
       "error: error while loading LogicalPlanVisitor, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/LogicalPlanVisitor.class)' has location not matching its contents: contains class LogicalPlanVisitor\n",
       "error: error while loading CoGroup, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/CoGroup.class)' has location not matching its contents: contains class CoGroup\n",
       "error: error while loading LocalRelation, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/LocalRelation.class)' has location not matching its contents: contains class LocalRelation\n",
       "error: error while loading View, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/View.class)' has location not matching its contents: contains class View\n",
       "error: error while loading RepartitionOperation, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/RepartitionOperation.class)' has location not matching its contents: contains class RepartitionOperation\n",
       "error: error while loading Aggregate, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Aggregate.class)' has location not matching its contents: contains class Aggregate\n",
       "error: error while loading Sort, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Sort.class)' has location not matching its contents: contains class Sort\n",
       "error: error while loading Repartition, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Repartition.class)' has location not matching its contents: contains class Repartition\n",
       "error: error while loading WithWindowDefinition, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/WithWindowDefinition.class)' has location not matching its contents: contains class WithWindowDefinition\n",
       "error: error while loading GroupingSets, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/GroupingSets.class)' has location not matching its contents: contains class GroupingSets\n",
       "error: error while loading Expand, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Expand.class)' has location not matching its contents: contains class Expand\n",
       "error: error while loading UnaryNode, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/UnaryNode.class)' has location not matching its contents: contains class UnaryNode\n",
       "error: error while loading Subquery, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Subquery.class)' has location not matching its contents: contains class Subquery\n",
       "error: error while loading ReturnAnswer, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ReturnAnswer.class)' has location not matching its contents: contains class ReturnAnswer\n",
       "error: error while loading MapElements, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/MapElements.class)' has location not matching its contents: contains class MapElements\n",
       "error: error while loading FlatMapGroupsWithState, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/FlatMapGroupsWithState.class)' has location not matching its contents: contains class FlatMapGroupsWithState\n",
       "error: error while loading Range, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Range.class)' has location not matching its contents: contains class Range\n",
       "error: error while loading Limit, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Limit.class)' has location not matching its contents: contains class Limit\n",
       "error: error while loading GlobalLimit, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/GlobalLimit.class)' has location not matching its contents: contains class GlobalLimit\n",
       "error: error while loading Deduplicate, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Deduplicate.class)' has location not matching its contents: contains class Deduplicate\n",
       "error: error while loading Project, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Project.class)' has location not matching its contents: contains class Project\n",
       "error: error while loading BinaryNode, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/BinaryNode.class)' has location not matching its contents: contains class BinaryNode\n",
       "error: error while loading Except, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Except.class)' has location not matching its contents: contains class Except\n",
       "error: error while loading CatalystSerde, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/CatalystSerde.class)' has location not matching its contents: contains class CatalystSerde\n",
       "error: error while loading NoTimeout, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/NoTimeout.class)' has location not matching its contents: contains class NoTimeout\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11689"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
