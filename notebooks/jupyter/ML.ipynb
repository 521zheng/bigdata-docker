{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking org.bdgenomics.adam:adam-core-spark2_2.11:0.24.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree-tmp-dir7387851658533337832/toree_add_deps/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree-tmp-dir7387851658533337832/toree_add_deps/https/repo1.maven.org/maven2/org/bdgenomics/adam/adam-core-spark2_2.11/0.24.0/adam-core-spark2_2.11-0.24.0.jar\n",
      "-> New file at /tmp/toree-tmp-dir7387851658533337832/toree_add_deps/https/repo1.maven.org/maven2/org/bdgenomics/adam/adam-core-spark2_2.11/0.24.0/adam-core-spark2_2.11-0.24.0.pom\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking comp.bio.aging:adam-playground_2.11:0.0.12 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree-tmp-dir7387851658533337832/toree_add_deps/\n",
      "-> https://dl.bintray.com/comp-bio-aging/main/\n",
      "-> https://repo1.maven.org/maven2\n",
      "Marking org.apache.hadoop:hadoop-azure:2.7.6 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree-tmp-dir7387851658533337832/toree_add_deps/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree-tmp-dir7387851658533337832/toree_add_deps/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure/2.7.6/hadoop-azure-2.7.6.jar\n",
      "-> New file at /tmp/toree-tmp-dir7387851658533337832/toree_add_deps/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure/2.7.6/hadoop-azure-2.7.6.pom\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Waiting for a Spark session to start..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%AddDeps org.bdgenomics.adam adam-core-spark2_2.11 0.24.0\n",
    "%AddDeps comp.bio.aging adam-playground_2.11 0.0.12 --repository https://dl.bintray.com/comp-bio-aging/main/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  org.apache.spark._\n",
    "import org.apache.spark.sql.{DataFrame, Encoders, SparkSession}\n",
    "import org.apache.spark.sql.types.StructType\n",
    "import scala.reflect.runtime.universe._\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "import org.apache.spark.rdd._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking org.apache.hadoop:hadoop-azure:2.7.6 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree-tmp-dir7387851658533337832/toree_add_deps/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree-tmp-dir7387851658533337832/toree_add_deps/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure/2.7.6/hadoop-azure-2.7.6.jar\n",
      "-> New file at /tmp/toree-tmp-dir7387851658533337832/toree_add_deps/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure/2.7.6/hadoop-azure-2.7.6.pom\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lastException: Throwable = null\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%AddDeps org.apache.hadoop hadoop-azure 2.7.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparkHadoopConf: (sc: org.apache.spark.SparkContext, acountName: String, accountKey: String)org.apache.spark.SparkContext\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sparkHadoopConf(sc: SparkContext, acountName: String, accountKey: String) = {\n",
    "  sc.hadoopConfiguration.set(\"fs.azure\", \"org.apache.hadoop.fs.azure.NativeAzureFileSystem\")\n",
    "  sc.hadoopConfiguration.set(\"fs.azure.account.key.\" + acountName + \".blob.core.windows.net\", accountKey)\n",
    "  sc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "azurize: (container: String, accountName: String, blobFile: String)String\n",
       "writeText2Azure: [T](rdd: org.apache.spark.rdd.RDD[T], container: String, accountName: String, blobFile: String)String\n",
       "writeTsv2Azure: (df: org.apache.spark.sql.DataFrame, container: String, accountName: String, blobFile: String)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def azurize(container: String, accountName: String, blobFile: String): String = \"wasbs://\"+container+\"@\"+accountName+\".blob.core.windows.net/\"+blobFile \n",
    "\n",
    "def writeText2Azure[T]( rdd: RDD[T], container: String, accountName: String, blobFile: String ): String =\n",
    "{\n",
    "  val url = azurize(container, accountName, blobFile)\n",
    "  rdd.saveAsTextFile(url)\n",
    "  url\n",
    "}\n",
    "\n",
    "def writeTsv2Azure( df: DataFrame, container: String, accountName: String, blobFile: String ): String =\n",
    "{\n",
    "  val url = azurize(container, accountName, blobFile)\n",
    "  df.write.option(\"sep\",\"\\t\").option(\"header\",\"true\").csv(url)\n",
    "  url\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key = ==\n",
       "connString = sDefaultEndpointsProtocol=https;AccountName=pipelines1;AccountKey=${key}==;EndpointSuffix=core.windows.net\n",
       "account = pipelines1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "az: (path: String)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "JHVfH9TNAcLhbIjVmIzT387Z2eAOFz1T0xvzJBb7z3jbWtMXspZD+E87OBDIvOyvnd8OWMdyPfKYSboGMKfIxQ=="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
      "val account = \"pipelines1\"\n",
       "val key = \"JHVfH9TNAcLhbIjVmIzT387Z2eAOFz1T0xvzJBb7z3jbWtMXspZD+E87OBDIvOyvnd8OWMdyPfKYSboGMKfIxQ==\"\n",
    "val connString = s\"DefaultEndpointsProtocol=https;AccountName=pipelines1;AccountKey=${key};EndpointSuffix=core.windows.net\"\n",
        "def az(path: String): String = azurize(\"storage\", account, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sparkContext = org.apache.spark.SparkContext@77760c55\n",
       "spark = org.apache.spark.sql.SparkSession@30a30d6d\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://fc9b3fce6198:4040)\" target=\"new_tab\">Spark UI: app-20180525142721-0011</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark app-20180525142721-0011: Some(http://fc9b3fce6198:4040)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sparkContext = sc\n",
    "sparkHadoopConf(sparkContext, account, key)\n",
    "  \n",
    "val spark = SparkSession\n",
    "  .builder()\n",
    "  .appName(\"mapping_models\")\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toDouble = UserDefinedFunction(<function1>,DoubleType,Some(List(StringType)))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "UserDefinedFunction(<function1>,DoubleType,Some(List(StringType)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import spark.implicits._\n",
    "\n",
    "val toDouble = udf[Double, String]( _.toDouble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gtexPath = /GTEx\n",
       "genesPath = wasbs://storage@pipelines1.blob.core.windows.net//GTEx/gtex_genes.tsv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "wasbs://storage@pipelines1.blob.core.windows.net//GTEx/gtex_genes.tsv"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val gtexPath = \"/GTEx\"\n",
    "val genesPath = az(gtexPath + \"/gtex_genes.tsv\")\n",
    "\n",
    "//val txtPath = az(gtexPath + \"/GTEx_Analysis_2016-01-15_v7_RSEMv1.2.22_transcript_tpm.txt\")\n",
    "//val gctPath = az(gtexPath + \"/GTEx_Analysis_2016-01-15_v7_RNASeQCv1.1.8_gene_tpm.gct\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readTSV: (path: String, header: Boolean, sep: String)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def readTSV(path: String, header: Boolean = false, sep: String = \"\\t\"): DataFrame = spark.read\n",
    "    .option(\"sep\", sep)\n",
    "    .option(\"comment\", \"#\")\n",
    "    .option(\"inferSchema\", true)\n",
    "    .option(\"header\", header)\n",
    "    .option(\"ignoreLeadingWhiteSpace\", true)\n",
    "    .option(\"ignoreTrailingWhiteSpace\", true)\n",
    "    .option(\"ignoreTrailingWhiteSpace\", true)\n",
    "    .option(\"maxColumns\", 150000)\n",
    "    .csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marking com.microsoft.azure:azure-storage:7.0.0 for download\n",
      "Preparing to fetch from:\n",
      "-> file:/tmp/toree-tmp-dir7387851658533337832/toree_add_deps/\n",
      "-> https://repo1.maven.org/maven2\n",
      "-> New file at /tmp/toree-tmp-dir7387851658533337832/toree_add_deps/https/repo1.maven.org/maven2/com/microsoft/azure/azure-storage/7.0.0/azure-storage-7.0.0.jar\n",
      "-> New file at /tmp/toree-tmp-dir7387851658533337832/toree_add_deps/https/repo1.maven.org/maven2/com/microsoft/azure/azure-storage/7.0.0/azure-storage-7.0.0.pom\n"
     ]
    }
   ],
   "source": [
    "%AddDeps com.microsoft.azure azure-storage 7.0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genes = [Name: string, ENSG00000223972.4: string ... 56201 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "error: error while loading KVIterator, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.3.0.jar(org/apache/spark/unsafe/KVIterator.class)' has location not matching its contents: contains class KVIterator\n",
       "error: error while loading UnsafeAlignedOffset, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.3.0.jar(org/apache/spark/unsafe/UnsafeAlignedOffset.class)' has location not matching its contents: contains class UnsafeAlignedOffset\n",
       "error: error while loading Platform, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.3.0.jar(org/apache/spark/unsafe/Platform.class)' has location not matching its contents: contains class Platform\n",
       "error: error while loading UTF8String, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.3.0.jar(org/apache/spark/unsafe/types/UTF8String.class)' has location not matching its contents: contains class UTF8String\n",
       "error: error while loading CalendarInterval, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.3.0.jar(org/apache/spark/unsafe/types/CalendarInterval.class)' has location not matching its contents: contains class CalendarInterval\n",
       "error: error while loading ByteArray, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-unsafe_2.11-2.3.0.jar(org/apache/spark/unsafe/types/ByteArray.class)' has location not matching its contents: contains class ByteArray\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[Name: string, ENSG00000223972.4: string ... 56201 more fields]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val genes = readTSV(genesPath, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "error: error while loading Cross, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/Cross.class)' has location not matching its contents: contains class Cross\n",
       "error: error while loading NaturalJoin, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/NaturalJoin.class)' has location not matching its contents: contains class NaturalJoin\n",
       "error: error while loading LeftExistence, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/LeftExistence.class)' has location not matching its contents: contains class LeftExistence\n",
       "error: error while loading RightOuter, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/RightOuter.class)' has location not matching its contents: contains class RightOuter\n",
       "error: error while loading LeftOuter, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/LeftOuter.class)' has location not matching its contents: contains class LeftOuter\n",
       "error: error while loading ExistenceJoin, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/ExistenceJoin.class)' has location not matching its contents: contains class ExistenceJoin\n",
       "error: error while loading InnerLike, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/InnerLike.class)' has location not matching its contents: contains class InnerLike\n",
       "error: error while loading JoinType, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/JoinType.class)' has location not matching its contents: contains class JoinType\n",
       "error: error while loading UsingJoin, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/UsingJoin.class)' has location not matching its contents: contains class UsingJoin\n",
       "error: error while loading FullOuter, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/FullOuter.class)' has location not matching its contents: contains class FullOuter\n",
       "error: error while loading LeftAnti, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/LeftAnti.class)' has location not matching its contents: contains class LeftAnti\n",
       "error: error while loading LeftSemi, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/LeftSemi.class)' has location not matching its contents: contains class LeftSemi\n",
       "error: error while loading Inner, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/Inner.class)' has location not matching its contents: contains class Inner\n",
       "error: error while loading QueryPlan, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/QueryPlan.class)' has location not matching its contents: contains class QueryPlan\n",
       "error: error while loading HintInfo, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/HintInfo.class)' has location not matching its contents: contains class HintInfo\n",
       "error: error while loading ColumnStat, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ColumnStat.class)' has location not matching its contents: contains class ColumnStat\n",
       "error: error while loading ScriptInputOutputSchema, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ScriptInputOutputSchema.class)' has location not matching its contents: contains class ScriptInputOutputSchema\n",
       "error: error while loading InsertIntoDir, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/InsertIntoDir.class)' has location not matching its contents: contains class InsertIntoDir\n",
       "error: error while loading LogicalPlan, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/LogicalPlan.class)' has location not matching its contents: contains class LogicalPlan\n",
       "error: error while loading Join, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Join.class)' has location not matching its contents: contains class Join\n",
       "error: error while loading FlatMapGroupsInPandas, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/FlatMapGroupsInPandas.class)' has location not matching its contents: contains class FlatMapGroupsInPandas\n",
       "error: error while loading LogicalGroupState, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/LogicalGroupState.class)' has location not matching its contents: contains class LogicalGroupState\n",
       "error: error while loading Pivot, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Pivot.class)' has location not matching its contents: contains class Pivot\n",
       "error: error while loading Generate, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Generate.class)' has location not matching its contents: contains class Generate\n",
       "error: error while loading AppendColumns, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/AppendColumns.class)' has location not matching its contents: contains class AppendColumns\n",
       "error: error while loading HistogramSerializer, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/HistogramSerializer.class)' has location not matching its contents: contains class HistogramSerializer\n",
       "error: error while loading Distinct, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Distinct.class)' has location not matching its contents: contains class Distinct\n",
       "error: error while loading Statistics, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Statistics.class)' has location not matching its contents: contains class Statistics\n",
       "error: error while loading SubqueryAlias, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/SubqueryAlias.class)' has location not matching its contents: contains class SubqueryAlias\n",
       "error: error while loading ObjectConsumer, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ObjectConsumer.class)' has location not matching its contents: contains class ObjectConsumer\n",
       "error: error while loading ProcessingTimeTimeout, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ProcessingTimeTimeout.class)' has location not matching its contents: contains class ProcessingTimeTimeout\n",
       "error: error while loading InsertIntoTable, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/InsertIntoTable.class)' has location not matching its contents: contains class InsertIntoTable\n",
       "error: error while loading MapGroups, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/MapGroups.class)' has location not matching its contents: contains class MapGroups\n",
       "error: error while loading Window, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Window.class)' has location not matching its contents: contains class Window\n",
       "error: error while loading DeserializeToObject, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/DeserializeToObject.class)' has location not matching its contents: contains class DeserializeToObject\n",
       "error: error while loading EventTimeTimeout, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/EventTimeTimeout.class)' has location not matching its contents: contains class EventTimeTimeout\n",
       "error: error while loading MapPartitionsInR, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/MapPartitionsInR.class)' has location not matching its contents: contains class MapPartitionsInR\n",
       "error: error while loading EventTimeWatermark, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/EventTimeWatermark.class)' has location not matching its contents: contains class EventTimeWatermark\n",
       "error: error while loading Sample, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Sample.class)' has location not matching its contents: contains class Sample\n",
       "error: error while loading AppendColumnsWithObject, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/AppendColumnsWithObject.class)' has location not matching its contents: contains class AppendColumnsWithObject\n",
       "error: error while loading Filter, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Filter.class)' has location not matching its contents: contains class Filter\n",
       "error: error while loading TypedFilter, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/TypedFilter.class)' has location not matching its contents: contains class TypedFilter\n",
       "error: error while loading Histogram, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Histogram.class)' has location not matching its contents: contains class Histogram\n",
       "error: error while loading AnalysisBarrier, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/AnalysisBarrier.class)' has location not matching its contents: contains class AnalysisBarrier\n",
       "error: error while loading With, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/With.class)' has location not matching its contents: contains class With\n",
       "error: error while loading MapPartitions, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/MapPartitions.class)' has location not matching its contents: contains class MapPartitions\n",
       "error: error while loading ResolvedHint, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ResolvedHint.class)' has location not matching its contents: contains class ResolvedHint\n",
       "error: error while loading LocalLimit, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/LocalLimit.class)' has location not matching its contents: contains class LocalLimit\n",
       "error: error while loading UnresolvedHint, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/UnresolvedHint.class)' has location not matching its contents: contains class UnresolvedHint\n",
       "error: error while loading Intersect, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Intersect.class)' has location not matching its contents: contains class Intersect\n",
       "error: error while loading OneRowRelation, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/OneRowRelation.class)' has location not matching its contents: contains class OneRowRelation\n",
       "error: error while loading SetOperation, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/SetOperation.class)' has location not matching its contents: contains class SetOperation\n",
       "error: error while loading ScriptTransformation, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ScriptTransformation.class)' has location not matching its contents: contains class ScriptTransformation\n",
       "error: error while loading HistogramBin, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/HistogramBin.class)' has location not matching its contents: contains class HistogramBin\n",
       "error: error while loading RepartitionByExpression, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/RepartitionByExpression.class)' has location not matching its contents: contains class RepartitionByExpression\n",
       "error: error while loading ObjectProducer, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ObjectProducer.class)' has location not matching its contents: contains class ObjectProducer\n",
       "error: error while loading FunctionUtils, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/FunctionUtils.class)' has location not matching its contents: contains class FunctionUtils\n",
       "error: error while loading FlatMapGroupsInR, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/FlatMapGroupsInR.class)' has location not matching its contents: contains class FlatMapGroupsInR\n",
       "error: error while loading Union, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Union.class)' has location not matching its contents: contains class Union\n",
       "error: error while loading LeafNode, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/LeafNode.class)' has location not matching its contents: contains class LeafNode\n",
       "error: error while loading SerializeFromObject, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/SerializeFromObject.class)' has location not matching its contents: contains class SerializeFromObject\n",
       "error: error while loading Command, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Command.class)' has location not matching its contents: contains class Command\n",
       "error: error while loading QueryPlanConstraints, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/QueryPlanConstraints.class)' has location not matching its contents: contains class QueryPlanConstraints\n",
       "error: error while loading LogicalPlanVisitor, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/LogicalPlanVisitor.class)' has location not matching its contents: contains class LogicalPlanVisitor\n",
       "error: error while loading CoGroup, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/CoGroup.class)' has location not matching its contents: contains class CoGroup\n",
       "error: error while loading LocalRelation, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/LocalRelation.class)' has location not matching its contents: contains class LocalRelation\n",
       "error: error while loading View, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/View.class)' has location not matching its contents: contains class View\n",
       "error: error while loading RepartitionOperation, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/RepartitionOperation.class)' has location not matching its contents: contains class RepartitionOperation\n",
       "error: error while loading Aggregate, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Aggregate.class)' has location not matching its contents: contains class Aggregate\n",
       "error: error while loading Sort, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Sort.class)' has location not matching its contents: contains class Sort\n",
       "error: error while loading Repartition, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Repartition.class)' has location not matching its contents: contains class Repartition\n",
       "error: error while loading WithWindowDefinition, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/WithWindowDefinition.class)' has location not matching its contents: contains class WithWindowDefinition\n",
       "error: error while loading GroupingSets, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/GroupingSets.class)' has location not matching its contents: contains class GroupingSets\n",
       "error: error while loading Expand, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Expand.class)' has location not matching its contents: contains class Expand\n",
       "error: error while loading UnaryNode, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/UnaryNode.class)' has location not matching its contents: contains class UnaryNode\n",
       "error: error while loading Subquery, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Subquery.class)' has location not matching its contents: contains class Subquery\n",
       "error: error while loading ReturnAnswer, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/ReturnAnswer.class)' has location not matching its contents: contains class ReturnAnswer\n",
       "error: error while loading MapElements, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/MapElements.class)' has location not matching its contents: contains class MapElements\n",
       "error: error while loading FlatMapGroupsWithState, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/FlatMapGroupsWithState.class)' has location not matching its contents: contains class FlatMapGroupsWithState\n",
       "error: error while loading Range, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Range.class)' has location not matching its contents: contains class Range\n",
       "error: error while loading Limit, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Limit.class)' has location not matching its contents: contains class Limit\n",
       "error: error while loading GlobalLimit, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/GlobalLimit.class)' has location not matching its contents: contains class GlobalLimit\n",
       "error: error while loading Deduplicate, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Deduplicate.class)' has location not matching its contents: contains class Deduplicate\n",
       "error: error while loading Project, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Project.class)' has location not matching its contents: contains class Project\n",
       "error: error while loading BinaryNode, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/BinaryNode.class)' has location not matching its contents: contains class BinaryNode\n",
       "error: error while loading Except, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/Except.class)' has location not matching its contents: contains class Except\n",
       "error: error while loading CatalystSerde, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/CatalystSerde.class)' has location not matching its contents: contains class CatalystSerde\n",
       "error: error while loading NoTimeout, class file '/usr/local/spark-2.3.0-bin-hadoop2.7/jars/spark-catalyst_2.11-2.3.0.jar(org/apache/spark/sql/catalyst/plans/logical/NoTimeout.class)' has location not matching its contents: contains class NoTimeout\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "11689"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
